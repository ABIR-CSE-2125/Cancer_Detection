{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../notebook/data/EHR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independented and target feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(columns=[\"Patient_ID\",\"Survival_Status\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder()\n",
    "lbl_transformer = LabelEncoder()\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
    "        (\"StandardScaler\", numeric_transformer, num_features),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lbl_transformer.fit_transform(df[\"Survival_Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for the best Params in the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lsgtc_model = LogisticRegression(max_iter=1000)\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs'],\n",
    "    'penalty': ['l2'],\n",
    "}\n",
    "bin_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear'],\n",
    "    'penalty': ['l2',\"l1\"],\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=lsgtc_model, param_grid=param_grid, cv=50, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "bin_gs = GridSearchCV(estimator=lsgtc_model,param_grid=bin_param_grid,cv = 10,n_jobs=-1, verbose=2)\n",
    "bin_gs.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=41)\n",
    "\n",
    "param_grid={\n",
    "    'criterion':[\"gini\",\"entropy\",\"log_loss\"],\n",
    "    \"splitter\":[\"best\",\"random\"],\n",
    "    \"max_depth\":[None,2,5,10, 20, 30, 40,],\n",
    "    'max_features': [None, 'sqrt', 'log2']  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = [5,10,15,20,25,30,40]\n",
    "insight = {\n",
    "}\n",
    "for cv in cvs:\n",
    "    dt_gscv = GridSearchCV(estimator=dt_model,param_grid=param_grid,cv=cv,n_jobs=-1,verbose=2)\n",
    "    dt_gscv.fit(X,y)\n",
    "    # print(f\"cv_val : {cv} --> best_score : {dt_gscv.best_score_}\")\n",
    "    insight[cv] ={\n",
    "    \"Score\" : dt_gscv.best_score_,\n",
    "    \"model\":dt_gscv.best_estimator_,\n",
    "    \"params\": dt_gscv.best_params_\n",
    "    } \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_df= pd.DataFrame(insight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    # \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(test_size,model,folds):\n",
    "    training_acc_list = []\n",
    "    testing_acc_list = []\n",
    "    for i in range(0,folds):\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=test_size)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        training_acc_list.append(accuracy_score(y_train,y_train_pred))\n",
    "        testing_acc_list.append(accuracy_score(y_test,y_test_pred))\n",
    "    # print(f\"testing_ accuracy_list : \",testing_acc_list)\n",
    "    # print(f\"training_accuracy_list : \",training_acc_list)\n",
    "    training_mean_accuracy = np.mean(training_acc_list)\n",
    "    testing_mean_accuracy = np.mean(testing_acc_list)\n",
    "    training_std_deviation = np.std(training_acc_list)\n",
    "    testing_std_deviation = np.std(testing_acc_list)\n",
    "    training_max_accuracy = np.max(training_acc_list)\n",
    "    testing_max_accuracy = np.max(testing_acc_list)\n",
    "    return (training_mean_accuracy,training_max_accuracy,training_std_deviation,testing_mean_accuracy,testing_max_accuracy,testing_std_deviation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = [10,25,35,50,65,80,100]\n",
    "test_size_list = [.10,.25,.33,.40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result={\n",
    "    \"model\":[],\n",
    "    \"No of Cross Validations\":[],\n",
    "    \"Test Size\":[],\n",
    "    \"Training Mean Accuracy\":[],\n",
    "    \"Training Max Accuracy\":[],\n",
    "    \"Testing Mean Accuracy\":[],\n",
    "    \"Testing Max Accuracy\":[],\n",
    "    \"Training Standard Deviation\":[],\n",
    "    \"Testing Standard Deviation\":[]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    for cv_fold in cv_folds:\n",
    "        for test_size in test_size_list:\n",
    "            training_mean_accuracy,training_max_accuracy,training_std_deviation,testing_mean_accuracy,testing_max_accuracy,testing_std_deviation = model_eval(model=model,test_size=test_size,folds=cv_fold)\n",
    "            print(f\"Model : {model_name} cross_val_folds : {cv_fold} test_size : {test_size}\")\n",
    "            print(\"Training Mean Accuracy\",training_mean_accuracy)\n",
    "            print(\"Training Max Accuracy\", training_max_accuracy)                \n",
    "            print(\"Training Standard Deviation\",training_std_deviation)\n",
    "            print(\"Testing Mean Accuracy\", testing_mean_accuracy)\n",
    "            print(\"Testing Max Accuracy\", testing_max_accuracy)\n",
    "            print(\"Testing Standard Deviation\",testing_std_deviation)\n",
    "            print(\"-\"*80)\n",
    "            result[\"model\"].append(model_name)\n",
    "            result[\"No of Cross Validations\"].append(cv_fold)\n",
    "            result[\"Test Size\"].append(test_size)\n",
    "            result[\"Training Mean Accuracy\"].append(round(training_mean_accuracy,4)),\n",
    "            result[\"Training Max Accuracy\"].append(round(training_max_accuracy,4)),\n",
    "            result[\"Training Standard Deviation\"].append(round(training_std_deviation,4)),\n",
    "            result[\"Testing Mean Accuracy\"].append(round(testing_mean_accuracy,4)),\n",
    "            result[\"Testing Max Accuracy\"].append(round(testing_max_accuracy,4)),\n",
    "            result[\"Testing Standard Deviation\"].append(round(testing_std_deviation,4)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.tail(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"../notebook/results/results.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
